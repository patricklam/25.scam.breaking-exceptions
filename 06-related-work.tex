While much program analysis research considers a single version of a software artifact, some related work treats changes between versions, and we discuss some related work in that area. We also discuss empirical efforts to detect and empirically survey the prevalence of breaking changes.

Logozzo et al~\cite{logozzo14:_verif_modul_version} proposed the concept of verification modulo versions. Like us, verification modulo versions recognizes that program verification need to recognize that software evolves over time and that verification tools must take this into account---in particular, a developer often wants to know about potential verification issues unique to new code, rather than re-triaging issues previously reported. A fundamental difference between their work and ours is that we put the interface between the client and the library at the centre of our approach, and ensure that changes in the library must be visible to the client before we report them, while the verification modulo versions approach aims to detect behavioural differences between two versions of some software.

Møller et al~\cite{møller20:_detec_locat_javas_progr_affec} propose a domain-specific language for JavaScript library developers to use to indicate to client developers what has changed in a new version of their library. Our work addresses a specific subset of the breaking changes problem but automatically deduces changes in the library that are relevant to a particular client. It does not require additional work on the part of the library developer. More generally, and at the same time, Lam et al~\cite{lam20:_puttin_seman_seman_version} proposed the development of semantic version calculators, including the usage of both traditional and lightweight contracts for libraries, to allow library developers to declare, and client developers to understand, the impact of potential breaking changes in libraries.

Jayasuriya et al~\cite{jayasuriya23:_under_break_chang_wild,jayasuriya24} investigate the prevalence of breaking changes in the wild. In principle, under semantic versioning~\cite{preston-werner23:_seman_version}, library developers ought to indicate breaking changes by incrementing the major version number (i.e. the first number in the version triplet); however, Jayasuriya et al found that 41.58\% of (syntactic) breaking changes were not identified as such, and that 11.58\% of changes were beaking.

We have proposed a static approach to detecting breaking changes. Mujahid et al~\cite{mujahid20:_using_other_tests_ident_break_updat} proposed a dynamic approach to this problem. Their goal is to answer the question of whether a new version includes breaking changes or not, and they combine tests from ``the crowd'' (a collection of other projects) to decide the question, finding that such tests indicated a breaking change 60\% of the time. Our approach is much more specific to a specific library/client pair, and aims to detect if library $X$'s upgrade may break client $Y$. More like us, Jayasuriya et al~\cite{jayasuriya24:_under_apis} also use a dynamic approach (compared to our static approach) on a client/library pair to detect behavioral breaking changes in the client using its tests, finding that 2.30\% of library updates broke the client.
